{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94511b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões iniciais: (410517, 12)\n",
      "\n",
      "✅ Dados de queimadas tratados:\n",
      "             DataHora  Satelite    Pais    Estado    Municipio     Bioma  \\\n",
      "0 2023-01-02 17:15:00  AQUA_M-T  BRASIL  AMAZONAS  ITACOATIARA  AMAZÔNIA   \n",
      "1 2023-01-02 17:30:00   NPP-375  BRASIL  AMAZONAS     CANUTAMA  AMAZÔNIA   \n",
      "2 2023-01-02 17:30:00   NPP-375  BRASIL  AMAZONAS     CANUTAMA  AMAZÔNIA   \n",
      "3 2023-01-03 18:00:00  AQUA_M-T  BRASIL  AMAZONAS    FONTE BOA  AMAZÔNIA   \n",
      "4 2023-01-03 18:00:00   NOAA-20  BRASIL  AMAZONAS         APUÍ  AMAZÔNIA   \n",
      "\n",
      "   DiaSemChuva  Precipitacao  RiscoFogo  Latitude  Longitude   FRP   ano  mes  \\\n",
      "0            0          0.80        0.0  -3.29169  -58.65920  19.1  2023    1   \n",
      "1            3          0.10        0.0  -8.76197  -64.16180   9.8  2023    1   \n",
      "2            3          0.10        0.0  -8.76593  -64.16123  28.0  2023    1   \n",
      "3            1          2.23     -999.0  -2.51782  -66.09596   7.2  2023    1   \n",
      "4            2          8.26        0.0  -8.56682  -59.62691   0.7  2023    1   \n",
      "\n",
      "   dia  hora  \n",
      "0    2    17  \n",
      "1    2    17  \n",
      "2    2    17  \n",
      "3    3    18  \n",
      "4    3    18  \n",
      "\n",
      "🔍 Valores faltantes após tratamento:\n",
      "FRP    8178\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Carregar a base de queimadas\n",
    "df_queimadas = pd.read_csv('C:/Users/Allyson/ENG4040/base_dados/queimadas_amazonas_2023.csv', encoding='utf-8')\n",
    "\n",
    "print(\"Dimensões iniciais:\", df_queimadas.shape)\n",
    "\n",
    "# 2. Converter DataHora para datetime\n",
    "df_queimadas['DataHora'] = pd.to_datetime(df_queimadas['DataHora'], format='%Y/%m/%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "# 3. Criar colunas auxiliares: ano, mês, dia, hora\n",
    "df_queimadas['ano'] = df_queimadas['DataHora'].dt.year\n",
    "df_queimadas['mes'] = df_queimadas['DataHora'].dt.month\n",
    "df_queimadas['dia'] = df_queimadas['DataHora'].dt.day\n",
    "df_queimadas['hora'] = df_queimadas['DataHora'].dt.hour\n",
    "\n",
    "# 4. Corrigir tipos numéricos\n",
    "colunas_float = ['Precipitacao', 'RiscoFogo', 'Latitude', 'Longitude', 'FRP']\n",
    "for col in colunas_float:\n",
    "    df_queimadas[col] = pd.to_numeric(df_queimadas[col], errors='coerce')\n",
    "\n",
    "df_queimadas['DiaSemChuva'] = pd.to_numeric(df_queimadas['DiaSemChuva'], errors='coerce', downcast='integer')\n",
    "\n",
    "# 5. Padronizar colunas de texto\n",
    "for col in ['Satelite', 'Pais', 'Estado', 'Municipio', 'Bioma']:\n",
    "    df_queimadas[col] = df_queimadas[col].str.strip().str.upper()\n",
    "\n",
    "# 6. Remover registros com dados essenciais ausentes\n",
    "df_queimadas = df_queimadas.dropna(subset=['DataHora', 'Municipio', 'Latitude', 'Longitude'])\n",
    "\n",
    "# 7. Visualizar resultado\n",
    "print(\"\\n✅ Dados de queimadas tratados:\")\n",
    "print(df_queimadas.head())\n",
    "\n",
    "print(\"\\n🔍 Valores faltantes após tratamento:\")\n",
    "print(df_queimadas.isna().sum()[df_queimadas.isna().sum() > 0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
