import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from scipy.stats import ttest_rel
import warnings
warnings.filterwarnings("ignore")

# === Configura√ß√µes ===
N_ITER = 1000  # N¬∫ de itera√ß√µes de bootstrap
TEST_SIZE = 0.3
RANDOM_STATE = 42

# === Caminhos ===
caminhos = {
    "Alta Sensibilidade": "Divisao/planilha_alta.csv",
    "M√©dia Sensibilidade": "Divisao/planilha_media.csv",
    "Baixa Sensibilidade": "Divisao/planilha_baixa.csv",
    "Todas as Doen√ßas": "Clustering/planilha/planilha_unificada_clusterizado.csv"
}

features = ["AREA_DESMATADA_KM2", "FRP", "RISCOFOGO", "PRECIPITACAO", "DIASEMCHUVA", "pm2.5_atm"]
target = "OBITOS"

# === Fun√ß√£o para calcular RMSE com bootstrap ===
def bootstrap_rmse(model, X, y, n_iter=N_ITER):
    rmses = []
    for _ in range(n_iter):
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        rmses.append(rmse)
    return np.array(rmses)

# === Loop nos grupos ===
for grupo, caminho in caminhos.items():
    print(f"\nüìä An√°lise Estat√≠stica - {grupo}")
    df = pd.read_csv(caminho)

    # Preparo
    df[target] = df[target].replace("-", np.nan)
    for col in features + [target]:
        df[col] = pd.to_numeric(df[col], errors="coerce")

    df = df[features + [target]].copy()
    for col in features + [target]:
        df[col] = df[col].fillna(df[col].median())

    scaler = StandardScaler()
    df[features] = scaler.fit_transform(df[features])

    X = df[features]
    y = df[target]

    # === Gerar distribui√ß√µes de RMSE ===
    modelo_lr = LinearRegression()
    modelo_rf = RandomForestRegressor(random_state=RANDOM_STATE)

    rmse_lr = bootstrap_rmse(modelo_lr, X, y)
    rmse_rf = bootstrap_rmse(modelo_rf, X, y)

    # === Intervalos de Confian√ßa 95% ===
    ci_lr = np.percentile(rmse_lr, [2.5, 97.5])
    ci_rf = np.percentile(rmse_rf, [2.5, 97.5])

    print(f"\nüìå Intervalo de Confian√ßa 95% (RMSE):")
    print(f"Linear Regression: [{ci_lr[0]:.4f}, {ci_lr[1]:.4f}]")
    print(f"Random Forest:     [{ci_rf[0]:.4f}, {ci_rf[1]:.4f}]")

    # === Teste de Hip√≥teses (t de Student pareado) ===
    stat, p_valor = ttest_rel(rmse_lr, rmse_rf)
    print(f"\nüß™ Teste de Hip√≥tese (LR vs RF):")
    print(f"Estat√≠stica t = {stat:.4f}")
    print(f"p-valor = {p_valor:.4f}")
    
    if p_valor < 0.05:
        print("‚Üí Diferen√ßa estatisticamente significativa (n√≠vel 5%)")
    else:
        print("‚Üí Diferen√ßa **n√£o** estatisticamente significativa (n√≠vel 5%)")


# -----------------------------
# Este c√≥digo realiza a compara√ß√£o entre os modelos Linear Regression e Random Forest 
# para cada grupo de doen√ßas (Alta, M√©dia, Baixa Sensibilidade e Todas as Doen√ßas) por meio de:
# 
# 1. Intervalo de Confian√ßa (IC 95%) para o RMSE:
#    ‚Üí Informa a faixa de valores mais prov√°veis para o erro m√©dio quadr√°tico de cada modelo.
#    ‚Üí Quanto menor e mais estreito o intervalo, mais confi√°vel e preciso o modelo √©.
# 
# 2. Teste de Hip√≥teses t pareado:
#    ‚Üí Verifica se h√° diferen√ßa estat√≠stica entre os modelos comparando as distribui√ß√µes de RMSE.
#    ‚Üí Um p-valor < 0.05 indica que a diferen√ßa de desempenho entre os modelos √© significativa.
#
# Interpreta√ß√£o pr√°tica:
# - Se a Regress√£o Linear tiver menor RMSE e a diferen√ßa for significativa, ela √© prefer√≠vel.
# - Se n√£o houver diferen√ßa significativa, ambos os modelos se equivalem para aquele grupo.
# 
# Assim, este c√≥digo ajuda a embasar a escolha dos modelos com testes estat√≠sticos robustos.

# As an√°lises foram feitas com 1000 itera√ß√µes de bootstrap dos RMSEs
# para Linear Regression e Random Forest em 4 grupos: Alta, M√©dia, Baixa Sensibilidade e Todas as Doen√ßas.
#
# 1. Alta Sensibilidade:
# - Linear Regression apresentou RMSE m√©dio menor e intervalo de confian√ßa mais baixo.
# - O teste t indicou p-valor = 0.0000 ‚Üí diferen√ßa estatisticamente significativa.
# Conclus√£o: Linear Regression √© superior ao Random Forest neste grupo.
#
# 2. M√©dia Sensibilidade:
# - Linear Regression tamb√©m teve melhor desempenho m√©dio e intervalo menor.
# - Teste t com p-valor = 0.0000 ‚Üí diferen√ßa significativa.
# Conclus√£o: Linear Regression √© estatisticamente superior neste grupo tamb√©m.
#
# 3. Baixa Sensibilidade:
# - Random Forest teve menor RMSE m√©dio, mas o teste t deu p-valor = 0.0819 (> 0.05).
# - N√£o h√° evid√™ncia estat√≠stica de superioridade entre os modelos.
# Conclus√£o: Ambos os modelos s√£o vi√°veis, sem diferen√ßa estat√≠stica relevante.
#
# 4. Todas as Doen√ßas (Clusterizado):
# - Linear Regression teve intervalo de confian√ßa mais favor√°vel.
# - Teste t com p-valor = 0.0000 ‚Üí diferen√ßa estatisticamente significativa.
# Conclus√£o: Linear Regression √© superior tamb√©m nesta base geral.
#
# Conclus√£o Final:
# - Linear Regression foi estatisticamente superior ao Random Forest nos grupos:
#   Alta Sensibilidade, M√©dia Sensibilidade e Todas as Doen√ßas.
# - Para Baixa Sensibilidade, os dois modelos s√£o equivalentes estatisticamente.
# - Linear Regression mostrou-se mais est√°vel e confi√°vel para este cen√°rio de dados.