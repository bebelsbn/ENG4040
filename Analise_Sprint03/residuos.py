# -------------------------------------------------------------------------------------------
# AN√ÅLISE DOS RES√çDUOS DO MODELO RANDOM FOREST - ALTA SENSIBILIDADE
#
# Objetivo:
# Avaliar a qualidade dos ajustes do modelo Random Forest para o grupo de doen√ßas
# respirat√≥rias de Alta Sensibilidade por meio da an√°lise dos res√≠duos (erros de previs√£o).
#
# Import√¢ncia no trabalho:
# A an√°lise dos res√≠duos √© essencial para verificar a presen√ßa de padr√µes n√£o capturados 
# pelo modelo, vi√©s sistem√°tico e poss√≠veis limita√ß√µes no desempenho preditivo. 
# Ajuda a identificar se o modelo est√° superestimando ou subestimando √≥bitos em certos cen√°rios.
#
# Etapas realizadas:
# - Leitura da base de dados da categoria Alta Sensibilidade
# - Imputa√ß√£o de valores ausentes com KNN (k=5)
# - Remo√ß√£o de colunas altamente correlacionadas (acima de 0.9)
# - Normaliza√ß√£o robusta com PowerTransformer (transforma√ß√£o n√£o linear)
# - Treinamento do modelo Random Forest
# - Gera√ß√£o de gr√°ficos para an√°lise dos res√≠duos:
#     * Boxplot para verificar simetria e outliers
#     * Dispers√£o dos res√≠duos vs valores preditos para avaliar vi√©s
# - C√°lculo das m√©tricas RMSE e R¬≤ para quantificar o desempenho
# -------------------------------------------------------------------------------------------

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, PowerTransformer
from sklearn.impute import KNNImputer
from sklearn.metrics import mean_squared_error, r2_score

# === Carrega a planilha ===
df = pd.read_csv("Divisao/planilha_alta.csv")

# === Define colunas relevantes ===
features = ["AREA_DESMATADA_KM2", "FRP", "RISCOFOGO", "PRECIPITACAO", "DIASEMCHUVA", "pm2.5_atm"]
target = "OBITOS"

# === Converte "-" em NaN e para valores num√©ricos ===
for col in features + [target]:
    df[col] = pd.to_numeric(df[col].replace("-", np.nan), errors="coerce")

# === Remove linhas sem target ===
df.dropna(subset=[target], inplace=True)

# === Imputa√ß√£o com KNN ===
imputer = KNNImputer(n_neighbors=5)
df[features] = imputer.fit_transform(df[features])

# === Remo√ß√£o de features com alta correla√ß√£o ===
corr = df[features].corr().abs()
upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))
features_corr_ok = [col for col in features if all(upper[col] < 0.9)]

# Se removeu todas, usa os originais
if not features_corr_ok:
    print("‚ö†Ô∏è Nenhuma vari√°vel sobrou ap√≥s verifica√ß√£o de correla√ß√£o. Usando todas.")
    features_corr_ok = features

df = df[features_corr_ok + [target]]

# === Normaliza√ß√£o robusta ===
scaler = PowerTransformer()
df[features_corr_ok] = scaler.fit_transform(df[features_corr_ok])

# === Treinamento ===
X = df[features_corr_ok]
y = df[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

modelo = RandomForestRegressor(random_state=42)
modelo.fit(X_train, y_train)
y_pred = modelo.predict(X_test)

# === C√°lculo dos res√≠duos ===
residuos = y_test - y_pred

# === Gr√°fico 1: Boxplot dos res√≠duos ===
plt.figure(figsize=(6, 5))
sns.boxplot(y=residuos)
plt.title("Boxplot dos Res√≠duos (Random Forest - Alta)")
plt.ylabel("Res√≠duos")
plt.tight_layout()
plt.savefig("boxplot_residuos_alta.png")
plt.show()

# === Gr√°fico 2: Dispers√£o dos res√≠duos ===
plt.figure(figsize=(7, 5))
sns.scatterplot(x=y_pred, y=residuos)
plt.axhline(0, color='red', linestyle='--')
plt.title("Dispers√£o dos Res√≠duos vs. Valores Preditos")
plt.xlabel("Valores Preditos")
plt.ylabel("Res√≠duos")
plt.tight_layout()
plt.savefig("dispersao_residuos_alta.png")
plt.show()

# === M√©tricas ===
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)
print(f"\nüìä RMSE = {rmse:.4f} | R¬≤ = {r2:.4f}")
